{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages (fastai for optimizing inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os\n",
    "from fastai.text import *\n",
    "import pandas as pd\n",
    "from fastai.tabular import *\n",
    "import sys\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.quick_load import *\n",
    "from architecture.model import *\n",
    "from architecture.helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location of processed DataBunch object from unsupervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = load_data(\"../saved/\", 'Reports_ALL.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to check input flags, and ask if not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"file\":\"\",\"dest\":\"\",'model':''}\n",
    "input_values=[]\n",
    "in_arr = sys.argv\n",
    "\n",
    "for arg in inputs:\n",
    "    if '-{}'.format(arg) not in in_arr:\n",
    "        inputs[arg] = str(input(\"-{}: \".format(arg)))\n",
    "    else: \n",
    "        inputs[arg] = in_arr[in_arr.index('-{}'.format(arg))+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of items to remove from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\"\\d+\", \"\\r\", \"\\n\",\"IMPRESSION:\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `interpret_IMPRESSION`:\n",
    "Function that formats report text to return a formatting that emphasizes important words, as destermined by saliency in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_IMPRESSION(text,thres,interp,red,black):\n",
    "    txt,attention = interp.intrinsic_attention(text)\n",
    "    important_word=[]\n",
    "    txt=str(txt).split(\" \")\n",
    "    index=0\n",
    "    for x in attention: \n",
    "        if 'xx' in txt[index]:\n",
    "            y=None\n",
    "        elif x.item()>thres:\n",
    "            important_word.append(red)\n",
    "            important_word.append(txt[index])\n",
    "            important_word.append(black)\n",
    "            important_word.append(\" \")\n",
    "        else:\n",
    "            if txt[index] is \" \":\n",
    "                attention.remove(txt[index])\n",
    "            else:\n",
    "                important_word.append(txt[index])\n",
    "                important_word.append(\" \")\n",
    "        index+=1\n",
    "    return important_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `load_CTHem_models`:\n",
    "- takes in the data object from the supervised training and loads the named model\n",
    "- specific `load_ccds_model` arguments:\n",
    "    - text_data = data object from unsupervised training (defined above)\n",
    "    - labeled_data = data object from supervised training (input for function)\n",
    "    - path_to_lm = path to language model (in `../saved/models`)\n",
    "    - path_to_classifier = name of classifier model (in `../saved/models`)\n",
    "    - **specific arguments if modified model**:\n",
    "        - *format of this list is `{argument}:{default_value} = {definition}*\n",
    "        - **encoding_size**:400 = size of encoding layer\n",
    "        - **layer_size**:1152 = size of encoder layers\n",
    "        - **num_layers**:3 = number of layers in encoder model\n",
    "        - **pad_token**:1 = padding token\n",
    "        - **hidden_dropout**:0.2 = dropout in hidden layer\n",
    "        - **input_dropout**:0.6 = dropout in input layer\n",
    "        - **embed_dropout**:0.1 = dropout in embedding layer\n",
    "        - **weight_dropout**:0.5 = dropout in weight layer\n",
    "        - **output_dropout**:0.1 = dropout in output layer\n",
    "        - **qrnn_cells**:bool=False = whether model has qrnn cells\n",
    "        - **bidirectional**:False = whether model is bidirectional\n",
    "        - **num_classes**:2 = number of classes for model (1 for regression)\n",
    "        - **decoder_layer_sizes**:[50] = list of layer sizes for decoder\n",
    "        - **decoder_dropout**:[0.1] = list of dropout values for decoder layers (should be single value or equal to length of layers\n",
    "        - **bptt_classifier**:70 = backprop through time, how many samples before gradient update\n",
    "        - **max_length**:2000 = max length of report document to feed in before splice\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CTHem_models(labeled_data,data_path,name):\n",
    "    try:\n",
    "        learn = load_ccds_model(text_data=text_data,\n",
    "                                labeled_data=labeled_data,\n",
    "                                path_to_lm='mod_all_reports_enc',\n",
    "                                path_to_classifier=name,\n",
    "                                decoder_layer_sizes=[50],\n",
    "                                decoder_dropout=[0.1]\n",
    "                                )\n",
    "    except:\n",
    "        learn = load_ccds_model(text_data=text_data,\n",
    "                                labeled_data=labeled_data,\n",
    "                                path_to_lm='mod_all_reports_enc',\n",
    "                                path_to_classifier=name,\n",
    "                                decoder_layer_sizes=[50],\n",
    "                                decoder_dropout=[0.1],\n",
    "                                num_classes=1\n",
    "                                )\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to generate relevant keywords based on saliency of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval_dropouts(mod):\n",
    "        module_name =  mod.__class__.__name__\n",
    "        if 'Dropout' in module_name or 'BatchNorm' in module_name: mod.training = False\n",
    "        for module in mod.children(): _eval_dropouts(module)\n",
    "            \n",
    "def intrinsic_attention(self, text, class_id=None):\n",
    "    self.model.train()\n",
    "    _eval_dropouts(self.model)\n",
    "    self.model.zero_grad()\n",
    "    self.model.reset()\n",
    "    ids = self.data.one_item(text)[0]\n",
    "    emb = self.model[0].module.encoder(ids).detach().requires_grad_(True)\n",
    "    lstm_output = self.model[0].module(emb, from_embeddings=True)\n",
    "    self.model.eval()\n",
    "    cl = self.model[1](lstm_output + (torch.zeros_like(ids).byte(),))[0].softmax(dim=-1)\n",
    "    if class_id is None: \n",
    "        class_id = cl.argmax()\n",
    "    cl[0][class_id].backward()\n",
    "    attn = emb.grad.squeeze().abs().sum(dim=-1)\n",
    "    attn /= attn.max()\n",
    "    tokens = self.data.single_ds.reconstruct(ids[0])\n",
    "    return tokens, attn\n",
    "\n",
    "def keywords_generator(text,thres,interp):\n",
    "    txt,attention = interp.intrinsic_attention(text)\n",
    "    important_words=[]\n",
    "    txt=str(txt).split(\" \")\n",
    "    index=0\n",
    "    for x in attention: \n",
    "        if x.item()>thres:\n",
    "            important_words.append(txt[index])\n",
    "        index+=1\n",
    "    return important_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create cohort folder:\n",
    "- **intervals** = list of numeric intervals to generate specific files based on model confidence\n",
    "- **file_names** = list of file names that correspond to the interval segments\n",
    "- **whole_file** = whether to save whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCohortFiles(data,learn,output_file,ranking_col='risk_score',intervals=[-np.inf,0.3,0.6,np.inf],file_names=['not_likely','possibly_likely','very_likely'],whole_file=True):\n",
    "    os.system('mkdir ../data/{}_cohort_tool'.format(output_file))\n",
    "    if whole_file:\n",
    "        data.to_csv('../data/{}_cohort_tool/full.csv'.format(output_file))\n",
    "    for cohort in range(len(intervals)-1):\n",
    "        test = data[(intervals[cohort]<= data[ranking_col]) & (data[ranking_col]<=intervals[cohort+1])]\n",
    "        test.reset_index(drop=True)\n",
    "        test.to_csv('../data/{}_cohort_tool/{}.csv'.format(output_file,file_names[cohort]),index=False)\n",
    "        test = pd.read_csv('../data/{}_cohort_tool/{}.csv'.format(output_file,file_names[cohort]))\n",
    "        test.reset_index(drop=True)\n",
    "        test.to_csv('../data/{}_cohort_tool/{}.csv'.format(output_file,file_names[cohort]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `report_generation` - function to generate reports:\n",
    "- **file** = input file, automatically set with arguments and functions above\n",
    "- **data_path** = path of folder of models\n",
    "- **bs** = batch size\n",
    "- **ranking** = whether to rank the reports based on confidence or not\n",
    "- **cohort** = whether to generate folder with all cohort samples\n",
    "- **risk_score** = whether to generate column of main model analysis\n",
    "- **predict** = whether to generate column of class predictions for main model (ints)\n",
    "- **binary_model_name** = name of main model, set in arguments up above\n",
    "- **prediction_thres** = prediction threshold defined between positive & negative to store when `predict = True`\n",
    "- **interpret** = whether to generate excel file with colored text on important words\n",
    "- **other_y_columns** = list of other models to generate necessary rows and prediction, should have same supervised data object stored with `{model_name}_data_clas_export.pkl` in the `../saved` folder\n",
    "- **key_words** = whether to generate key_words for reports\n",
    "- **interpret_thres** = what the saliency threshold is to add a word to key_words or interpret\n",
    "- **output_file** - output file name, set in previous arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_generation(file=inputs['file'],\n",
    "                      data_path='../saved',\n",
    "                      bs=128,\n",
    "                      ranking=False, \n",
    "                      cohort=True,\n",
    "                      risk_score=True, \n",
    "                      predict=True,\n",
    "                      binary_model_name=inputs['model'],\n",
    "                      prediction_thres=0.5,\n",
    "                      interpret=True, \n",
    "                      other_y_columns=[],\n",
    "                      key_words=False,\n",
    "                      interpret_thres=0.6,\n",
    "                      output_file=inputs['dest']):\n",
    "    data = pd.read_csv(file)\n",
    "    data = clean_impressions(data,'IMPRESSION',to_remove)\n",
    "    writer = pd.ExcelWriter('../data/{}_cohort_tool/output_file{}'.format(output_file,'.xlsx'), engine='xlsxwriter')\n",
    "    workbook  = writer.book\n",
    "    print('Loading Data...')\n",
    "    binary_data_clas = load_data(data_path, '{}_data_clas_export.pkl'.format(binary_model_name), bs=bs)\n",
    "    print('Done')\n",
    "    print('Loading Models...')\n",
    "    binary_model = load_CTHem_models(binary_data_clas,data_path,'CTHem')\n",
    "    print('Done')\n",
    "    if ranking or risk_score:\n",
    "        print('Evaluating File...')\n",
    "        data['risk_score'] = data['IMPRESSION'].progress_apply(lambda x: float(binary_model.predict(x)[2][1]))\n",
    "        print('Done')\n",
    "        if ranking:\n",
    "            print('Ranking File...')\n",
    "            data = data.sort_values(by=['risk_score'],ascending=False)\n",
    "            print('Done')\n",
    "    if len(other_y_columns) != 0:\n",
    "        print('Predicting File...')\n",
    "        for output in other_y_columns:\n",
    "            print(\"Predicting: {}\".format(output.upper()))\n",
    "            multi_data_clas = load_data(data_path, '{}_data_clas_export.pkl'.format(output), bs=64)\n",
    "            multi_model = load_CTHem_models(multi_data_clas,data_path,output)\n",
    "            data[\"{}_preds\".format(output)] = data['IMPRESSION'].progress_apply(lambda x: round(float(multi_model.predict(x)[1]),2))\n",
    "            print('Done')\n",
    "    if predict:\n",
    "        print('Predicting File...')\n",
    "        data['prediction'] = data['risk_score'].progress_apply(lambda x: int(x>prediction_thres))\n",
    "    if not risk_score:\n",
    "            data.drop('risk_score')  \n",
    "    if cohort:\n",
    "        createCohortFiles(data,binary_model,output_file)\n",
    "    if key_words or interpret:\n",
    "        interp = TextClassificationInterpretation.from_learner(binary_model) \n",
    "        if key_words:\n",
    "            print('Generating Keywords...')\n",
    "            data['Keywords'] = data['IMPRESSION'].progress_apply(lambda x: keywords_generator(x,interpret_thres,interp))\n",
    "            print('Done')\n",
    "        if interpret:\n",
    "            print('Interpreting File...')\n",
    "            data['Interpret'] = ''\n",
    "            red = workbook.add_format({'color': 'red'})\n",
    "            black = workbook.add_format({'color': 'black'})\n",
    "            data['Interpret'] = data['IMPRESSION'].progress_apply(lambda x: interpret_IMPRESSION(x,interpret_thres,interp,red,black))\n",
    "            data.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "            worksheet = writer.sheets['Sheet1']\n",
    "            for idx, x in data['Interpret'].iteritems():\n",
    "                worksheet.write_rich_string(idx+1, len(data.columns)-1, *x)\n",
    "            writer.save()\n",
    "    data.to_excel(writer, sheet_name='Sheet1', index=False) \n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    writer.save()\n",
    "    print('File Done')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = report_generation(interpret=False,ranking=False,binary_model_name=inputs['model'],other_y_columns=['EDH','IPH','IVH','SAH','SDH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
