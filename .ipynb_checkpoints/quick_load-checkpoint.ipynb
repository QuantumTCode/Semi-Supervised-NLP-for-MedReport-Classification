{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from architecture.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ccds_model(text_data:DataBunch=None,\n",
    "                    labeled_data:DataBunch=None,\n",
    "                    path_to_lm:str=None,\n",
    "                    path_to_classifier:str=None,\n",
    "                    encoding_size:int=400,\n",
    "                    layer_size:int=1152,\n",
    "                    num_layers:int=3,\n",
    "                    pad_token:int=1,\n",
    "                    hidden_p:float=0.2,\n",
    "                    input_p:float=0.6,\n",
    "                    embed_p:float=0.1,\n",
    "                    weight_p:float=0.5,\n",
    "                    output_dropout:float=0.1,\n",
    "                    qrnn:bool=False, \n",
    "                    bidir:bool=False,\n",
    "                    num_classes:int=2,\n",
    "                    decoder_layer_sizes:Collection[int]=[64,32],\n",
    "                    decoder_dropout:Collection[float]=[0.1,0.1],\n",
    "                    bptt_classifier:int=70,\n",
    "                    max_length:int=2000):\n",
    "    \n",
    "    vocab_size = len(text_data.vocab.itos)\n",
    "    \n",
    "    encoder = us_ccds_encoder(vocab_sz=vocab_size,\n",
    "                          enc_sz=encoding_size, \n",
    "                          n_hid=layer_size, \n",
    "                          n_layers=num_layers, \n",
    "                          pad_token=pad_token, \n",
    "                          hidden_p=hidden_dropout,\n",
    "                          input_p=input_dropout, \n",
    "                          embed_p=embed_dropout, \n",
    "                          weight_p=weight_dropout, \n",
    "                          qrnn=qrnn_cells, \n",
    "                          bidir=bidirectional)\n",
    "    \n",
    "    \n",
    "    decoder = us_ccds_decoder(n_out=vocab_size, \n",
    "                          n_hid=encoding_size, \n",
    "                          output_p=output_dropout, \n",
    "                          tie_encoder=encoder.encoder, \n",
    "                          bias=True)\n",
    "    \n",
    "    custom_model = SequentialRNN(encoder,decoder)\n",
    "    learn_awd = LanguageLearner(text_data, custom_model)\n",
    "    learn_awd.model = custom_model.cuda()\n",
    "    \n",
    "    learn_awd.load(path_to_lm)\n",
    "    \n",
    "    pretrained = learn_awd.model[0]\n",
    "    encoder = us_ccds_encoder(bptt=bptt_classifier, \n",
    "                              max_len=max_length,\n",
    "                              custom_model=pretrained,\n",
    "                              pad_idx=pad_token)\n",
    "    decoder = us_ccds_decoder(num_classes,\n",
    "                              lin_ftrs=decoder_layer_sizes,\n",
    "                              ps=decoder_dropout)\n",
    "    \n",
    "    learn = text_classifier_learner(labeled_data)\n",
    "    learn.save('path_to_classifier')\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
